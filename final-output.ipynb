{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-03-11T05:51:45.205404Z","iopub.status.busy":"2025-03-11T05:51:45.205105Z","iopub.status.idle":"2025-03-11T05:54:38.871232Z","shell.execute_reply":"2025-03-11T05:54:38.870215Z","shell.execute_reply.started":"2025-03-11T05:51:45.205381Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in links: /kaggle/input/vllm-0-6-3-post1-wheels\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/torchvision-0.19.1-cp310-cp310-manylinux1_x86_64.whl\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.19.1) (1.26.4)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl (from torchvision==0.19.1)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.19.1) (11.0.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision==0.19.1) (3.17.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision==0.19.1) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision==0.19.1) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision==0.19.1) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision==0.19.1) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision==0.19.1) (2024.12.0)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (from torch==2.4.1->torchvision==0.19.1)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (from torch==2.4.1->torchvision==0.19.1)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (from torch==2.4.1->torchvision==0.19.1)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (from torch==2.4.1->torchvision==0.19.1)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (from torch==2.4.1->torchvision==0.19.1)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (from torch==2.4.1->torchvision==0.19.1)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (from torch==2.4.1->torchvision==0.19.1)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (from torch==2.4.1->torchvision==0.19.1)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (from torch==2.4.1->torchvision==0.19.1)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (from torch==2.4.1->torchvision==0.19.1)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (from torch==2.4.1->torchvision==0.19.1)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from torch==2.4.1->torchvision==0.19.1)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.1->torchvision==0.19.1) (12.6.85)\n","Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision==0.19.1) (1.3.8)\n","Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision==0.19.1) (1.2.4)\n","Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision==0.19.1) (0.1.1)\n","Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision==0.19.1) (2025.0.1)\n","Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision==0.19.1) (2022.0.0)\n","Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision==0.19.1) (2.4.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.1->torchvision==0.19.1) (3.0.2)\n","Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision==0.19.1) (2024.2.0)\n","Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision==0.19.1) (2022.0.0)\n","Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torchvision==0.19.1) (1.2.0)\n","Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torchvision==0.19.1) (2024.2.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.1->torchvision==0.19.1) (1.3.0)\n","Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torchvision==0.19.1) (2024.2.0)\n","Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.23.4\n","    Uninstalling nvidia-nccl-cu12-2.23.4:\n","      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n","    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.7.77\n","    Uninstalling nvidia-curand-cu12-10.3.7.77:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n","    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n","      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n","    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n","    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n","    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n","      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n","    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.6.0.74\n","    Uninstalling nvidia-cudnn-cu12-9.6.0.74:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.6.0.74\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.5.1+cu121\n","    Uninstalling torch-2.5.1+cu121:\n","      Successfully uninstalled torch-2.5.1+cu121\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.20.1+cu121\n","    Uninstalling torchvision-0.20.1+cu121:\n","      Successfully uninstalled torchvision-0.20.1+cu121\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","pylibcugraph-cu12 24.10.0 requires pylibraft-cu12==24.10.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n","pylibcugraph-cu12 24.10.0 requires rmm-cu12==24.10.*, but you have rmm-cu12 25.2.0 which is incompatible.\n","torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.4.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.4.1 torchvision-0.19.1 triton-3.0.0\n","Looking in links: /kaggle/input/vllm-0-6-3-post1-wheels\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/vllm-0.6.3.post1-cp38-abi3-manylinux1_x86_64.whl\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from vllm) (5.9.5)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from vllm) (0.2.0)\n","Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (1.26.4)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from vllm) (4.67.1)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from vllm) (9.0.0)\n","Requirement already satisfied: transformers>=4.45.2 in /usr/local/lib/python3.10/dist-packages (from vllm) (4.47.0)\n","Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.21.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from vllm) (3.20.3)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from vllm) (3.11.12)\n","Requirement already satisfied: openai>=1.40.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (1.57.4)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/uvicorn-0.32.0-py3-none-any.whl (from vllm)\n","Requirement already satisfied: pydantic>=2.9 in /usr/local/lib/python3.10/dist-packages (from vllm) (2.11.0a2)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from vllm) (11.0.0)\n","Requirement already satisfied: prometheus-client>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.21.1)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/prometheus_fastapi_instrumentator-7.0.0-py3-none-any.whl (from vllm)\n","Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.9.0)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/lm_format_enforcer-0.10.6-py3-none-any.whl (from vllm)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/outlines-0.0.46-py3-none-any.whl (from vllm)\n","Requirement already satisfied: typing-extensions>=4.10 in /usr/local/lib/python3.10/dist-packages (from vllm) (4.12.2)\n","Requirement already satisfied: filelock>=3.10.4 in /usr/local/lib/python3.10/dist-packages (from vllm) (3.17.0)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/partial_json_parser-0.2.1.1.post4-py3-none-any.whl (from vllm)\n","Requirement already satisfied: pyzmq in /usr/local/lib/python3.10/dist-packages (from vllm) (24.0.1)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/msgspec-0.18.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from vllm)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/gguf-0.10.0-py3-none-any.whl (from vllm)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from vllm) (8.5.0)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/mistral_common-1.4.4-py3-none-any.whl (from mistral-common[opencv]>=1.4.4->vllm)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from vllm) (6.0.2)\n","Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from vllm) (0.8.0)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/compressed_tensors-0.6.0-py3-none-any.whl (from vllm)\n","Requirement already satisfied: ray>=2.9 in /usr/local/lib/python3.10/dist-packages (from vllm) (2.42.1)\n","Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.10/dist-packages (from vllm) (12.570.86)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl (from vllm)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/torchvision-0.19.0-cp310-cp310-manylinux1_x86_64.whl (from vllm)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/xformers-0.0.27.post2-cp310-cp310-manylinux2014_x86_64.whl (from vllm)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/fastapi-0.115.3-py3-none-any.whl (from vllm)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/interegular-0.3.3-py37-none-any.whl (from lm-format-enforcer==0.10.6->vllm)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lm-format-enforcer==0.10.6->vllm) (24.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (2024.12.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (12.1.105)\n","Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->vllm) (3.0.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0->vllm) (12.6.85)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/starlette-0.41.0-py3-none-any.whl (from fastapi!=0.113.*,!=0.114.0,>=0.107.0->vllm)\n","Requirement already satisfied: jsonschema<5.0.0,>=4.21.1 in /usr/local/lib/python3.10/dist-packages (from mistral-common>=1.4.4->mistral-common[opencv]>=1.4.4->vllm) (4.23.0)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (from vllm)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from vllm)\n","Requirement already satisfied: opencv-python-headless<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mistral-common[opencv]>=1.4.4->vllm) (4.10.0.84)\n","Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0->vllm) (1.3.8)\n","Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0->vllm) (1.2.4)\n","Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0->vllm) (0.1.1)\n","Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0->vllm) (2025.0.1)\n","Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0->vllm) (2022.0.0)\n","Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0->vllm) (2.4.1)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.40.0->vllm) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.40.0->vllm) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.40.0->vllm) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.40.0->vllm) (0.8.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.40.0->vllm) (1.3.1)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/lark-1.2.2-py3-none-any.whl (from outlines<0.1,>=0.0.43->vllm)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (1.6.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (3.1.0)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/diskcache-5.6.3-py3-none-any.whl (from outlines<0.1,>=0.0.43->vllm)\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (0.60.0)\n","Requirement already satisfied: referencing in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (0.35.1)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (3.3.1)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/pycountry-24.6.1-py3-none-any.whl (from outlines<0.1,>=0.0.43->vllm)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/pyairports-2.1.1-py3-none-any.whl (from outlines<0.1,>=0.0.43->vllm)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9->vllm) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9->vllm) (2.29.0)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (8.1.7)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (1.1.0)\n","Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (1.3.2)\n","Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (1.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->vllm) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->vllm) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->vllm) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->vllm) (2025.1.31)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken>=0.6.0->vllm) (2024.11.6)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.19.1->vllm) (0.29.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.45.2->vllm) (0.4.5)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (2.4.6)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (5.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (25.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (1.18.3)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->vllm) (3.21.0)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (0.14.0)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from uvicorn[standard]->vllm)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/python_dotenv-1.0.1-py3-none-any.whl (from uvicorn[standard]->vllm)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from uvicorn[standard]->vllm)\n","Processing /kaggle/input/vllm-0-6-3-post1-wheels/watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from uvicorn[standard]->vllm)\n","Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (14.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.40.0->vllm) (1.2.2)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.40.0->vllm) (1.0.7)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.21.1->mistral-common>=1.4.4->mistral-common[opencv]>=1.4.4->vllm) (2024.10.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.21.1->mistral-common>=1.4.4->mistral-common[opencv]>=1.4.4->vllm) (0.22.3)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (19.0.1)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (2.2.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (0.70.16)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.0->vllm) (3.0.2)\n","Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0.0->vllm) (2024.2.0)\n","Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0.0->vllm) (2022.0.0)\n","Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2.0.0->vllm) (1.2.0)\n","Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2.0.0->vllm) (2024.2.0)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->outlines<0.1,>=0.0.43->vllm) (0.43.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.0->vllm) (1.3.0)\n","Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2.0.0->vllm) (2024.2.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm) (2025.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->outlines<0.1,>=0.0.43->vllm) (1.17.0)\n","Installing collected packages: pyairports, uvloop, uvicorn, python-dotenv, pycountry, pillow, partial-json-parser, msgspec, lark, interegular, httptools, diskcache, watchfiles, tiktoken, starlette, torch, prometheus-fastapi-instrumentator, lm-format-enforcer, fastapi, mistral-common, xformers, torchvision, outlines, gguf, compressed-tensors, vllm\n","  Attempting uninstall: pillow\n","    Found existing installation: pillow 11.0.0\n","    Uninstalling pillow-11.0.0:\n","      Successfully uninstalled pillow-11.0.0\n","  Attempting uninstall: tiktoken\n","    Found existing installation: tiktoken 0.9.0\n","    Uninstalling tiktoken-0.9.0:\n","      Successfully uninstalled tiktoken-0.9.0\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.4.1\n","    Uninstalling torch-2.4.1:\n","      Successfully uninstalled torch-2.4.1\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.19.1\n","    Uninstalling torchvision-0.19.1:\n","      Successfully uninstalled torchvision-0.19.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","mlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\n","plotnine 0.14.4 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\n","torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed compressed-tensors-0.6.0 diskcache-5.6.3 fastapi-0.115.3 gguf-0.10.0 httptools-0.6.4 interegular-0.3.3 lark-1.2.2 lm-format-enforcer-0.10.6 mistral-common-1.4.4 msgspec-0.18.6 outlines-0.0.46 partial-json-parser-0.2.1.1.post4 pillow-10.4.0 prometheus-fastapi-instrumentator-7.0.0 pyairports-2.1.1 pycountry-24.6.1 python-dotenv-1.0.1 starlette-0.41.0 tiktoken-0.7.0 torch-2.4.0 torchvision-0.19.0 uvicorn-0.32.0 uvloop-0.21.0 vllm-0.6.3.post1 watchfiles-0.24.0 xformers-0.0.27.post2\n"]}],"source":["!pip install --no-index --find-links=/kaggle/input/vllm-0-6-3-post1-wheels torchvision==0.19.1\n","!pip install --no-index --find-links=/kaggle/input/vllm-0-6-3-post1-wheels vllm"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2025-03-11T05:55:33.825259Z","iopub.status.busy":"2025-03-11T05:55:33.824885Z","iopub.status.idle":"2025-03-11T05:55:53.299787Z","shell.execute_reply":"2025-03-11T05:55:53.299183Z","shell.execute_reply.started":"2025-03-11T05:55:33.825223Z"},"trusted":true},"outputs":[],"source":["from transformers import AutoTokenizer\n","from vllm import LLM, SamplingParams"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2025-03-11T05:56:02.868686Z","iopub.status.busy":"2025-03-11T05:56:02.868368Z","iopub.status.idle":"2025-03-11T05:56:03.014033Z","shell.execute_reply":"2025-03-11T05:56:03.013236Z","shell.execute_reply.started":"2025-03-11T05:56:02.868663Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Logged in successfully!\n"]}],"source":["# Optional: Log in to Hugging Face (using your token)\n","from huggingface_hub import login\n","hf_token = \"token\"\n","login(token=hf_token)\n","print(\"Logged in successfully!\")"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2025-03-11T05:56:05.863095Z","iopub.status.busy":"2025-03-11T05:56:05.862667Z","iopub.status.idle":"2025-03-11T05:56:07.297871Z","shell.execute_reply":"2025-03-11T05:56:07.297231Z","shell.execute_reply.started":"2025-03-11T05:56:05.863059Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ee6ba09fa948496b8e7d3d5994c583fa","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"08a9dadc6c304f4a9498f7c7eca9bb5f","version_major":2,"version_minor":0},"text/plain":["tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3a801393d5104ec083ac4816f10fb2fd","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2d3900f4f3184ec194f0710a001e7ef7","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Initialize the tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\"TheBloke/Mistral-7B-Instruct-v0.2-AWQ\")"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2025-03-11T05:56:09.971539Z","iopub.status.busy":"2025-03-11T05:56:09.971244Z","iopub.status.idle":"2025-03-11T05:56:09.975400Z","shell.execute_reply":"2025-03-11T05:56:09.974445Z","shell.execute_reply.started":"2025-03-11T05:56:09.971519Z"},"trusted":true},"outputs":[],"source":["sampling_params = SamplingParams(temperature=0.7, top_p=0.8, repetition_penalty=1.05, max_tokens=512)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2025-03-11T05:56:12.483958Z","iopub.status.busy":"2025-03-11T05:56:12.483654Z","iopub.status.idle":"2025-03-11T05:57:36.911942Z","shell.execute_reply":"2025-03-11T05:57:36.911016Z","shell.execute_reply.started":"2025-03-11T05:56:12.483934Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"95eefd3d07ac4e77932197b22605e839","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/904 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["WARNING 03-11 05:56:22 config.py:321] awq quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n","INFO 03-11 05:56:22 llm_engine.py:237] Initializing an LLM engine (v0.6.3.post1) with config: model='TheBloke/Mistral-7B-Instruct-v0.2-AWQ', speculative_config=None, tokenizer='TheBloke/Mistral-7B-Instruct-v0.2-AWQ', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=awq, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=TheBloke/Mistral-7B-Instruct-v0.2-AWQ, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=False, mm_processor_kwargs=None)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c8e726b3fde44a06acdd40e647a0e71d","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["INFO 03-11 05:56:23 selector.py:224] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n","INFO 03-11 05:56:23 selector.py:115] Using XFormers backend.\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n","  @torch.library.impl_abstract(\"xformers_flash::flash_fwd\")\n","/usr/local/lib/python3.10/dist-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n","  @torch.library.impl_abstract(\"xformers_flash::flash_bwd\")\n"]},{"name":"stdout","output_type":"stream","text":["INFO 03-11 05:56:24 model_runner.py:1056] Starting to load model TheBloke/Mistral-7B-Instruct-v0.2-AWQ...\n","INFO 03-11 05:56:24 selector.py:224] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n","INFO 03-11 05:56:24 selector.py:115] Using XFormers backend.\n","INFO 03-11 05:56:24 weight_utils.py:243] Using model weights format ['*.safetensors']\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2352d3720972473a90f95d3058e8c31f","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/4.15G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["INFO 03-11 05:56:33 weight_utils.py:288] No model.safetensors.index.json found in remote.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"672c77aaedf34a1ea98ed9c5bb30c290","version_major":2,"version_minor":0},"text/plain":["Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["INFO 03-11 05:56:35 model_runner.py:1067] Loading model weights took 3.8814 GB\n","INFO 03-11 05:56:52 gpu_executor.py:122] # GPU blocks: 2186, # CPU blocks: 2048\n","INFO 03-11 05:56:52 gpu_executor.py:126] Maximum concurrency for 32768 tokens per request: 1.07x\n","INFO 03-11 05:56:56 model_runner.py:1395] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n","INFO 03-11 05:56:56 model_runner.py:1399] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n","INFO 03-11 05:57:36 model_runner.py:1523] Graph capturing finished in 40 secs.\n"]}],"source":["# Input the model name or path. Can be GPTQ or AWQ models.\n","llm = LLM(model=\"TheBloke/Mistral-7B-Instruct-v0.2-AWQ\",\n","         dtype=\"half\")\n","\n","#ValueError: Bfloat16 is only supported on GPUs with compute capability of at least 8.0. \n","# Your b'Tesla T4' GPU has compute capability 7.5. You can use float16 instead by explicitly setting the`dtype` flag in CLI, for example: --dtype=half."]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2025-03-11T06:04:48.835217Z","iopub.status.busy":"2025-03-11T06:04:48.834803Z","iopub.status.idle":"2025-03-11T06:04:49.020253Z","shell.execute_reply":"2025-03-11T06:04:49.019519Z","shell.execute_reply.started":"2025-03-11T06:04:48.835189Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Survey Structure: A concept testing survey evaluating consumer reactions to ULTRA Pure Gold, a new premium light beer positioned as a 'Superior Light Beer' with low carbs (2.6g) and calories (85), among adults aged 21-65 who consume alcoholic beverages.\n","\n","USER PERSONA  \n","- Male, 33.0, Big city, Income: $40,000 to $49,999\n","- Alcohol Types Consumed over last 4 weeks: Beer, Distilled Spirits\n","- Beer Types Consumed over last 4 weeks: Domestic Regular Beer, Imported Mexican Beer\n","\n","PRODUCT PREFERENCE  \n","- Relevance: Neutral & Appeal: Neither Appealing nor Unappealing\n","- Differentiation: Somewhat Different & Not Very Believable\n","- Price: About Average\n","- Purchase Intent: Definitely Would Not Buy\n","- Consumption (if free): Never\n","- Replacement Preference: Be used in addition to products you are currently using\n","\n","USER RESPONSES  \n","- *Like:* \"Price and presentation\"\n","- *Dislike:* \"Taste\"\n","\n","Evaluation Criteria:  \n","- *Contradiction:*   \n","- *Overly Positive:*   \n","- *Vague Response:* Minimal detail in \"dislike\" response  \n","- *Lack of Depth:* \"Like\" is clear, \"Dislike\" is brief  \n","- *Inconsistencies:* None  \n","- *Low Effort:* \"Dislike\" response is minimal \n","\n","Flag the response ( 1 = Bad Response, 0 = Good response,) and only return flag(either 0 or 1).\n","\n"]}],"source":["import pandas as pd\n","df = pd.read_excel(\"/kaggle/input/final-validation-dataset/Final Data File_Validation.xlsx\")\n","df = df.drop(index=0).reset_index(drop=True)\n","\n","Age = df['Q1. What is your current age? \\n(Age)']\n","Gender = df['Q2. What is your gender? \\n(Gender)']\n","Urban_Rural = df['Q3. Which of the following best describes the area or community in which you live? \\n(Urban/Rural)']\n","Income = df['Q4.  Please indicate the answer that includes your entire household income in (previous year) before taxes. \\n(Income)']\n","\n","# Question 6 Sub-parameters\n","Beer = df['Q6 Which of the following types of alcoholic beverages have you consumed in the past 4 weeks?\\n(Alcohol Category)']\n","Flavored_Mixed_Beer = df['Unnamed: 8']\n","Non_Alcoholic_Beers = df['Unnamed: 9']\n","Hard_Ciders = df['Unnamed: 10']\n","Hard_Kombucha = df['Unnamed: 11']\n","Wine = df['Unnamed: 12']\n","Hard_Beverage = df['Unnamed: 13']\n","Distilled_Spirits = df['Unnamed: 14']\n","\n","# Question 7 Sub-parameters\n","Domestic_Light_Beer = df['Q7. Which of the following beer types of have you consumed in the past 4 weeks? \\n(Beer Category )']\n","Domestic_Regular_Beer = df['Unnamed: 16']\n","Low_Calorie_Carb_Beer = df['Unnamed: 17']\n","Domestic_Craft = df['Unnamed: 18']\n","Imported_Mexican_Beer = df['Unnamed: 19']\n","Other_Imported_Beer = df['Unnamed: 20']\n","Non_Alcoholic_Beer = df['Unnamed: 21']\n","\n","# Question 9-15\n","Concept_Relevance = df['Q9. How relevant would you say the shown product is to you based on what you saw and read?\\n(Concept Relevance)']\n","Concept_Appeal = df['Q10. How appealing or unappealing is the shown product  to you?\\n(Concept Appeal)']\n","Concept_Differentiation = df['Q11. How different do you think the shown product is from other beers currently available for purchase?\\n(Concept Differentiation)']\n","Concept_Beleivability = df['Q12. Thinking about the shown product, which option describes how believable or unbelievable you feel the description and statements made about it are?\\n(Concept Beleivability)']\n","Concept_Price = df['Q13. How does the price fit with what you’d expect the shown to cost?\\n(Concept_Price)']\n","Concept_Purchase_Intent = df['Q14. Which statement below best describes how likely you would be to buy shown product if it were available at your local stores?\\n(Concept_Purchase Intent)']\n","Concept_Drinking_Frequency = df['Q15. If the shwon product was available to you, how often would you expect yourself to drink at least one of these products?\\n(Concept_Drinking Frequency)']\n","\n","# Question 16A, 16B\n","Like = df['Q16A. What is the most important thing you LIKE about the shown concept}?     This can include anything you would want kept for sure or aspects that might drive you to buy or try it…       Please type a detailed response in the space below']\n","Dislike = df['Q16B. What is the most important thing you DISLIKE about the shown concept}?    This can include general concerns, annoyances, or any aspects of the product that need fixed for this to be more appealing to you...     Please type a detailed response in the space below.']\n","\n","# Question 17\n","Concept_Replacement_Product = df['Q17. We would like to know what effect this new product might have on the other beverages you buy. If it were available, would the shown product…? \\n(Concept_Replacement Product)']\n","\n","Survery_Structure = \"A concept testing survey evaluating consumer reactions to ULTRA Pure Gold, a new premium light beer positioned as a 'Superior Light Beer' with low carbs (2.6g) and calories (85), among adults aged 21-65 who consume alcoholic beverages.\"\n","\n","def generate_prompt(row_number):\n","    # Extract the row data as a Series\n","    row = df.iloc[row_number]\n","\n","    # Identify consumed alcoholic beverages (Q6)\n","    alcohol_columns = {\n","        \"Beer\": \"Q6 Which of the following types of alcoholic beverages have you consumed in the past 4 weeks?\\n(Alcohol Category)\",\n","        \"Flavored Mixed Beer\": \"Unnamed: 8\",\n","        \"Non-Alcoholic Beers\": \"Unnamed: 9\",\n","        \"Hard Ciders\": \"Unnamed: 10\",\n","        \"Hard Kombucha\": \"Unnamed: 11\",\n","        \"Wine\": \"Unnamed: 12\",\n","        \"Hard Beverage\": \"Unnamed: 13\",\n","        \"Distilled Spirits\": \"Unnamed: 14\"\n","    }\n","    \n","    consumed_alcohol = [name for name, col in alcohol_columns.items() if row[col] == \"Yes\"]\n","    consumed_alcohol_str = \", \".join(consumed_alcohol) if consumed_alcohol else \"None\"\n","\n","    # Identify consumed beer categories (Q7)\n","    beer_columns = {\n","        \"Domestic Light Beer\": \"Q7. Which of the following beer types of have you consumed in the past 4 weeks? \\n(Beer Category )\",\n","        \"Domestic Regular Beer\": \"Unnamed: 16\",\n","        \"Low-Calorie/Carb Beer\": \"Unnamed: 17\",\n","        \"Domestic Craft\": \"Unnamed: 18\",\n","        \"Imported Mexican Beer\": \"Unnamed: 19\",\n","        \"Other Imported Beer\": \"Unnamed: 20\",\n","        \"Non-Alcoholic Beer\": \"Unnamed: 21\"\n","    }\n","\n","    consumed_beers = [name for name, col in beer_columns.items() if row[col] == \"Yes\"]\n","    consumed_beers_str = \", \".join(consumed_beers) if consumed_beers else \"None\"\n","\n","    # Create a dynamic prompt using str.format()\n","    prompt = \"\"\"\n","Survey Structure: {Survery_Structure}\n","\n","USER PERSONA  \n","- {Gender}, {Age}, {Urban_Rural}, Income: {Income}\n","- Alcohol Types Consumed over last 4 weeks: {consumed_alcohol_str}\n","- Beer Types Consumed over last 4 weeks: {consumed_beers_str}\n","\n","PRODUCT PREFERENCE  \n","- Relevance: {Concept_Relevance} & Appeal: {Concept_Appeal}\n","- Differentiation: {Concept_Differentiation} & {Concept_Beleivability}\n","- Price: {Concept_Price}\n","- Purchase Intent: {Concept_Purchase_Intent}\n","- Consumption (if free): {Concept_Drinking_Frequency}\n","- Replacement Preference: {Concept_Replacement_Product}\n","\n","USER RESPONSES  \n","- *Like:* \"{Like}\"\n","- *Dislike:* \"{Dislike}\"\n","\n","Evaluation Criteria:  \n","- *Contradiction:*   \n","- *Overly Positive:*   \n","- *Vague Response:* Minimal detail in \"dislike\" response  \n","- *Lack of Depth:* \"Like\" is clear, \"Dislike\" is brief  \n","- *Inconsistencies:* None  \n","- *Low Effort:* \"Dislike\" response is minimal \n","\n","Flag the response ( 1 = Bad Response, 0 = Good response,) and only return flag(either 0 or 1).\n","\"\"\".format(\n","        Survery_Structure=Survery_Structure,\n","        Gender=row['Q2. What is your gender? \\n(Gender)'],\n","        Age=row['Q1. What is your current age? \\n(Age)'],\n","        Urban_Rural=row['Q3. Which of the following best describes the area or community in which you live? \\n(Urban/Rural)'],\n","        Income=row['Q4.  Please indicate the answer that includes your entire household income in (previous year) before taxes. \\n(Income)'],\n","        consumed_alcohol_str=consumed_alcohol_str,\n","        consumed_beers_str=consumed_beers_str,\n","        Concept_Relevance=row['Q9. How relevant would you say the shown product is to you based on what you saw and read?\\n(Concept Relevance)'],\n","        Concept_Appeal=row['Q10. How appealing or unappealing is the shown product  to you?\\n(Concept Appeal)'],\n","        Concept_Differentiation=row['Q11. How different do you think the shown product is from other beers currently available for purchase?\\n(Concept Differentiation)'],\n","        Concept_Beleivability=row['Q12. Thinking about the shown product, which option describes how believable or unbelievable you feel the description and statements made about it are?\\n(Concept Beleivability)'],\n","        Concept_Price=row['Q13. How does the price fit with what you’d expect the shown to cost?\\n(Concept_Price)'],\n","        Concept_Purchase_Intent=row['Q14. Which statement below best describes how likely you would be to buy shown product if it were available at your local stores?\\n(Concept_Purchase Intent)'],\n","        Concept_Drinking_Frequency=row['Q15. If the shwon product was available to you, how often would you expect yourself to drink at least one of these products?\\n(Concept_Drinking Frequency)'],\n","        Concept_Replacement_Product=row['Q17. We would like to know what effect this new product might have on the other beverages you buy. If it were available, would the shown product…? \\n(Concept_Replacement Product)'],\n","        Like=row['Q16A. What is the most important thing you LIKE about the shown concept}?     This can include anything you would want kept for sure or aspects that might drive you to buy or try it…       Please type a detailed response in the space below'],\n","        Dislike=row['Q16B. What is the most important thing you DISLIKE about the shown concept}?    This can include general concerns, annoyances, or any aspects of the product that need fixed for this to be more appealing to you...     Please type a detailed response in the space below.']\n","    )\n","\n","    return prompt\n","\n","row_number = 79  # Change this to the desired row index\n","print(generate_prompt(row_number))\n","llm_prompt = generate_prompt(row_number)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2025-03-11T06:05:00.407481Z","iopub.status.busy":"2025-03-11T06:05:00.407154Z","iopub.status.idle":"2025-03-11T06:05:00.412419Z","shell.execute_reply":"2025-03-11T06:05:00.411481Z","shell.execute_reply.started":"2025-03-11T06:05:00.407458Z"},"trusted":true},"outputs":[],"source":["# Prepare your prompts\n","# prompt = \"\"\"\n","# *USER PERSONA*  \n","# A Male, 45, from Suburban / just outside of a city, earning $60,000 to $69,999 in the last 4 weeks, consumed Beer & Domestic Regular Beer.\n","\n","# *USER PRODUCT PREFERENCE*  \n","# Based on their preference, the product is Completely Relevant To Me & Extremely Appealing, being Very Different & Very Believable. At an About Average price & Probably Would Buy, and if free, would drink it Daily/Nightly. If choosing a replacement, they'd prefer Sometimes replace products you are currently drinking.\n","\n","# *OPEN ENDED ANSWER BY THE USER*\n","\n","# *Question 1:* What is the most important thing you LIKE about the shown concept? This can include anything you would want kept for sure or aspects that might drive you to buy or try it…  \n","# *Answer 1:* Taste crispy.\n","\n","# *Question 2:* What is the most important thing you DISLIKE about the shown concept? This can include general concerns, annoyances, or any aspects of the product that need fixing for this to be more appealing to you…  \n","# *Answer 2:* Don’t.\n","\n","# *Parameters to check:*  \n","# Contradiction: None detected.  \n","# Overly Positive Response: The \"like\" response is brief but positive, while the \"dislike\" response is vague and lacks detail.  \n","# Vague Response: \"Don’t\" is an incomplete response and does not clarify what is disliked.  \n","# Lack of Depth: Both answers are minimal. \"Taste crispy\" is positive, but \"Don’t\" lacks context or further explanation.  \n","# Inconsistencies: None detected, but the responses could be considered unclear due to lack of depth.  \n","# Low Effort/Minimal Response: Both answers are short and do not provide detailed feedback.\n","\n","# *flag this response as 0 or 1 (0 = positive, 1 = negative) and only return the output and nothing else.*\n","# \"\"\"\n","messages = [\n","    {\n","        \"role\": \"user\",\n","        \"content\": \"You are an evaluator which will help me in classifying user response for a beer survey.\\n\\n\" + llm_prompt \n","    },\n","    {\"role\": \"assistant\", \"content\": \"\"}  # Placeholder to ensure correct formatting\n","]\n","\n","\n","text = tokenizer.apply_chat_template(\n","    messages,\n","    tokenize=False,\n","    add_generation_prompt=True\n",")"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2025-03-11T06:05:08.471732Z","iopub.status.busy":"2025-03-11T06:05:08.471354Z","iopub.status.idle":"2025-03-11T06:05:09.152783Z","shell.execute_reply":"2025-03-11T06:05:09.152097Z","shell.execute_reply.started":"2025-03-11T06:05:08.471705Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 2/2 [00:00<00:00,  2.97it/s, est. speed input: 1255.59 toks/s, output: 2.98 toks/s][A\u001b[A\u001b[A\n"]}],"source":["# generate outputs\n","outputs = llm.generate([text], sampling_params)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2025-03-11T06:05:12.455735Z","iopub.status.busy":"2025-03-11T06:05:12.455395Z","iopub.status.idle":"2025-03-11T06:05:12.461171Z","shell.execute_reply":"2025-03-11T06:05:12.460183Z","shell.execute_reply.started":"2025-03-11T06:05:12.455709Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Prompt: '<s>[INST] You are an evaluator which will help me in classifying user response for a beer survey.\\n\\n\\nSurvey Structure: A concept testing survey evaluating consumer reactions to ULTRA Pure Gold, a new premium light beer positioned as a \\'Superior Light Beer\\' with low carbs (2.6g) and calories (85), among adults aged 21-65 who consume alcoholic beverages.\\n\\nUSER PERSONA  \\n- Male, 33.0, Big city, Income: $40,000 to $49,999\\n- Alcohol Types Consumed over last 4 weeks: Beer, Distilled Spirits\\n- Beer Types Consumed over last 4 weeks: Domestic Regular Beer, Imported Mexican Beer\\n\\nPRODUCT PREFERENCE  \\n- Relevance: Neutral & Appeal: Neither Appealing nor Unappealing\\n- Differentiation: Somewhat Different & Not Very Believable\\n- Price: About Average\\n- Purchase Intent: Definitely Would Not Buy\\n- Consumption (if free): Never\\n- Replacement Preference: Be used in addition to products you are currently using\\n\\nUSER RESPONSES  \\n- *Like:* \"Price and presentation\"\\n- *Dislike:* \"Taste\"\\n\\nEvaluation Criteria:  \\n- *Contradiction:*   \\n- *Overly Positive:*   \\n- *Vague Response:* Minimal detail in \"dislike\" response  \\n- *Lack of Depth:* \"Like\" is clear, \"Dislike\" is brief  \\n- *Inconsistencies:* None  \\n- *Low Effort:* \"Dislike\" response is minimal \\n\\nFlag the response ( 1 = Bad Response, 0 = Good response,) and only return flag(either 0 or 1).\\n [/INST]</s>', Generated text: '0'\n","Prompt: '<s>[INST] You are an evaluator which will help me in classifying user response for a beer survey.\\n\\n\\nSurvey Structure: A concept testing survey evaluating consumer reactions to ULTRA Pure Gold, a new premium light beer positioned as a \\'Superior Light Beer\\' with low carbs (2.6g) and calories (85), among adults aged 21-65 who consume alcoholic beverages.\\n\\nUSER PERSONA  \\n- Male, 33.0, Big city, Income: $40,000 to $49,999\\n- Alcohol Types Consumed over last 4 weeks: Beer, Distilled Spirits\\n- Beer Types Consumed over last 4 weeks: Domestic Regular Beer, Imported Mexican Beer\\n\\nPRODUCT PREFERENCE  \\n- Relevance: Neutral & Appeal: Neither Appealing nor Unappealing\\n- Differentiation: Somewhat Different & Not Very Believable\\n- Price: About Average\\n- Purchase Intent: Definitely Would Not Buy\\n- Consumption (if free): Never\\n- Replacement Preference: Be used in addition to products you are currently using\\n\\nUSER RESPONSES  \\n- *Like:* \"Price and presentation\"\\n- *Dislike:* \"Taste\"\\n\\nEvaluation Criteria:  \\n- *Contradiction:*   \\n- *Overly Positive:*   \\n- *Vague Response:* Minimal detail in \"dislike\" response  \\n- *Lack of Depth:* \"Like\" is clear, \"Dislike\" is brief  \\n- *Inconsistencies:* None  \\n- *Low Effort:* \"Dislike\" response is minimal \\n\\nFlag the response ( 1 = Bad Response, 0 = Good response,) and only return flag(either 0 or 1).\\n [/INST]</s>', Generated text: '0'\n"]}],"source":["# Print the outputs.\n","for output in outputs:\n","    prompt = output.prompt\n","    generated_text = output.outputs[0].text\n","    print(f\"Prompt: {prompt!r}, Generated text: {generated_text!r}\")"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2025-03-11T06:05:14.818058Z","iopub.status.busy":"2025-03-11T06:05:14.817676Z","iopub.status.idle":"2025-03-11T06:05:15.528578Z","shell.execute_reply":"2025-03-11T06:05:15.527710Z","shell.execute_reply.started":"2025-03-11T06:05:14.817998Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s, est. speed input: 604.76 toks/s, output: 1.43 toks/s]\u001b[A\u001b[A\u001b[A"]},{"name":"stdout","output_type":"stream","text":["Generated text: '0'\n","Response Time: 0.71 seconds\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["import time\n","\n","# Measure response time\n","start_time = time.time()\n","outputs = llm.generate([text], sampling_params)\n","end_time = time.time()\n","\n","# Print the outputs\n","for output in outputs:\n","    generated_text = output.outputs[0].text\n","    print(f\"Generated text: {generated_text!r}\")\n","\n","# Print response time\n","response_time = end_time - start_time\n","print(f\"Response Time: {response_time:.2f} seconds\")"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2025-03-11T06:05:18.623632Z","iopub.status.busy":"2025-03-11T06:05:18.623342Z","iopub.status.idle":"2025-03-11T06:05:19.328964Z","shell.execute_reply":"2025-03-11T06:05:19.328201Z","shell.execute_reply.started":"2025-03-11T06:05:18.623611Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s, est. speed input: 610.59 toks/s, output: 1.45 toks/s]\u001b[A\u001b[A\u001b[A"]},{"name":"stdout","output_type":"stream","text":["Generated text: '1'\n","Response Time: 0.70 seconds\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["from vllm import SamplingParams\n","\n","# Ensure LLM only outputs 0 or 1 using logits\n","logit_bias = {28734: 100, 28740: 100}  # Force high probability for '0' and '1'\n","\n","sampling_params = SamplingParams(\n","    temperature=0.0,  # No randomness\n","    top_k=2,          # Only consider '0' and '1'\n","    logit_bias=logit_bias,\n","    max_tokens=1,      # Ensure single-token response\n",")\n","\n","# Generate outputs\n","start_time = time.time()\n","outputs = llm.generate([text], sampling_params)  # Now passing correct object type\n","end_time = time.time()\n","\n","# Extract predicted token\n","generated_token_id = outputs[0].outputs[0].token_ids[0]\n","generated_text = tokenizer.decode([generated_token_id])\n","\n","# Print response\n","print(f\"Generated text: {generated_text!r}\")\n","print(f\"Response Time: {end_time - start_time:.2f} seconds\")\n"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2025-03-11T06:07:26.656084Z","iopub.status.busy":"2025-03-11T06:07:26.655700Z","iopub.status.idle":"2025-03-11T06:07:26.661310Z","shell.execute_reply":"2025-03-11T06:07:26.660484Z","shell.execute_reply.started":"2025-03-11T06:07:26.656053Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407]\n"]}],"source":["result=[]\n","rows =[]\n","for i in range(1,len(df)):\n","    rows.append(i)\n","print(rows)"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2025-03-11T06:18:57.656656Z","iopub.status.busy":"2025-03-11T06:18:57.656268Z","iopub.status.idle":"2025-03-11T06:19:27.454164Z","shell.execute_reply":"2025-03-11T06:19:27.452882Z","shell.execute_reply.started":"2025-03-11T06:18:57.656626Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s, est. speed input: 709.82 toks/s, output: 1.40 toks/s]\u001b[A\u001b[A\u001b[A\n"]},{"name":"stdout","output_type":"stream","text":["0\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s, est. speed input: 614.67 toks/s, output: 1.16 toks/s]\u001b[A\u001b[A\u001b[A\n"]},{"name":"stdout","output_type":"stream","text":["0\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s, est. speed input: 711.10 toks/s, output: 1.43 toks/s]\u001b[A\u001b[A\u001b[A\n"]},{"name":"stdout","output_type":"stream","text":["0\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s, est. speed input: 694.74 toks/s, output: 1.37 toks/s]\u001b[A\u001b[A\u001b[A\n"]},{"name":"stdout","output_type":"stream","text":["1\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s, est. speed input: 683.48 toks/s, output: 1.38 toks/s]\u001b[A\u001b[A\u001b[A\n"]},{"name":"stdout","output_type":"stream","text":["0\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s, est. speed input: 595.59 toks/s, output: 1.12 toks/s]\u001b[A\u001b[A\u001b[A\n"]},{"name":"stdout","output_type":"stream","text":["0\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s, est. speed input: 673.01 toks/s, output: 1.34 toks/s]\u001b[A\u001b[A\u001b[A\n"]},{"name":"stdout","output_type":"stream","text":["0\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s, est. speed input: 584.86 toks/s, output: 1.10 toks/s]\u001b[A\u001b[A\u001b[A\n"]},{"name":"stdout","output_type":"stream","text":["0\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s, est. speed input: 662.65 toks/s, output: 1.33 toks/s]\u001b[A\u001b[A\u001b[A\n"]},{"name":"stdout","output_type":"stream","text":["0\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s, est. speed input: 608.11 toks/s, output: 1.07 toks/s]\u001b[A\u001b[A\u001b[A\n"]},{"name":"stdout","output_type":"stream","text":["0\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s, est. speed input: 632.77 toks/s, output: 1.33 toks/s]\u001b[A\u001b[A\u001b[A\n"]},{"name":"stdout","output_type":"stream","text":["1\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s, est. speed input: 578.08 toks/s, output: 1.07 toks/s]\u001b[A\u001b[A\u001b[A\n"]},{"name":"stdout","output_type":"stream","text":["0\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s, est. speed input: 551.82 toks/s, output: 1.07 toks/s]\u001b[A\u001b[A\u001b[A\n"]},{"name":"stdout","output_type":"stream","text":["0\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s, est. speed input: 627.95 toks/s, output: 1.30 toks/s]\u001b[A\u001b[A\u001b[A\n"]},{"name":"stdout","output_type":"stream","text":["0\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s, est. speed input: 627.37 toks/s, output: 1.29 toks/s]\u001b[A\u001b[A\u001b[A\n"]},{"name":"stdout","output_type":"stream","text":["0\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s, est. speed input: 574.79 toks/s, output: 1.04 toks/s]\u001b[A\u001b[A\u001b[A\n"]},{"name":"stdout","output_type":"stream","text":["0\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s, est. speed input: 606.21 toks/s, output: 1.30 toks/s]\u001b[A\u001b[A\u001b[A\n"]},{"name":"stdout","output_type":"stream","text":["0\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s, est. speed input: 640.08 toks/s, output: 1.26 toks/s]\u001b[A\u001b[A\u001b[A\n"]},{"name":"stdout","output_type":"stream","text":["0\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s, est. speed input: 610.70 toks/s, output: 1.28 toks/s]\u001b[A\u001b[A\u001b[A\n"]},{"name":"stdout","output_type":"stream","text":["0\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.04it/s, est. speed input: 550.87 toks/s, output: 1.04 toks/s]\u001b[A\u001b[A\u001b[A\n"]},{"name":"stdout","output_type":"stream","text":["0\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s, est. speed input: 623.62 toks/s, output: 1.28 toks/s]\u001b[A\u001b[A\u001b[A\n"]},{"name":"stdout","output_type":"stream","text":["0\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s, est. speed input: 625.42 toks/s, output: 1.26 toks/s]\u001b[A\u001b[A\u001b[A\n"]},{"name":"stdout","output_type":"stream","text":["0\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s, est. speed input: 643.66 toks/s, output: 1.26 toks/s]\u001b[A\u001b[A\u001b[A\n"]},{"name":"stdout","output_type":"stream","text":["0\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s, est. speed input: 548.04 toks/s, output: 1.06 toks/s]\u001b[A\u001b[A\u001b[A\n"]},{"name":"stdout","output_type":"stream","text":["0\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s, est. speed input: 650.43 toks/s, output: 1.28 toks/s]\u001b[A\u001b[A\u001b[A\n"]},{"name":"stdout","output_type":"stream","text":["0\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s, est. speed input: 633.58 toks/s, output: 1.31 toks/s]\u001b[A\u001b[A\u001b[A\n"]},{"name":"stdout","output_type":"stream","text":["0\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s, est. speed input: 628.59 toks/s, output: 1.33 toks/s]\u001b[A\u001b[A\u001b[A\n"]},{"name":"stdout","output_type":"stream","text":["0\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s, est. speed input: 668.96 toks/s, output: 1.31 toks/s]\u001b[A\u001b[A\u001b[A\n"]},{"name":"stdout","output_type":"stream","text":["0\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s, est. speed input: 648.78 toks/s, output: 1.33 toks/s]\u001b[A\u001b[A\u001b[A\n"]},{"name":"stdout","output_type":"stream","text":["0\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s, est. speed input: 665.76 toks/s, output: 1.34 toks/s]\u001b[A\u001b[A\u001b[A\n"]},{"name":"stdout","output_type":"stream","text":["0\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s, est. speed input: 680.27 toks/s, output: 1.35 toks/s]\u001b[A\u001b[A\u001b[A\n"]},{"name":"stdout","output_type":"stream","text":["0\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s, est. speed input: 672.00 toks/s, output: 1.37 toks/s]\u001b[A\u001b[A\u001b[A\n"]},{"name":"stdout","output_type":"stream","text":["0\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s, est. speed input: 672.79 toks/s, output: 1.38 toks/s]\u001b[A\u001b[A\u001b[A\n"]},{"name":"stdout","output_type":"stream","text":["1\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s, est. speed input: 602.63 toks/s, output: 1.13 toks/s]\u001b[A\u001b[A\u001b[A\n"]},{"name":"stdout","output_type":"stream","text":["1\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s, est. speed input: 706.26 toks/s, output: 1.41 toks/s]\u001b[A\u001b[A\u001b[A\n"]},{"name":"stdout","output_type":"stream","text":["0\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","Processed prompts: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s, est. speed input: 681.30 toks/s, output: 1.44 toks/s]\u001b[A\u001b[A\u001b[A\n"]},{"name":"stdout","output_type":"stream","text":["0\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","\n","Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\u001b[A\u001b[A"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-38-176357fb537a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m      \u001b[0;31m# Ensure single-token response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     )\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mgenerated_token_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mgenerated_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgenerated_token_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/utils.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1061\u001b[0m                     )\n\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/entrypoints/llm.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, sampling_params, prompt_token_ids, use_tqdm, lora_request, prompt_adapter_request, guided_options_request, priority)\u001b[0m\n\u001b[1;32m    351\u001b[0m             priority=priority)\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_tqdm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_tqdm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mLLMEngine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRequestOutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/entrypoints/llm.py\u001b[0m in \u001b[0;36m_run_engine\u001b[0;34m(self, use_tqdm)\u001b[0m\n\u001b[1;32m    877\u001b[0m         \u001b[0mtotal_out_toks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_unfinished_requests\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m             \u001b[0mstep_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstep_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinished\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/engine/llm_engine.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                     virtual_engine]\n\u001b[1;32m   1388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m             outputs = self.model_executor.execute_model(\n\u001b[0m\u001b[1;32m   1390\u001b[0m                 execute_model_req=execute_model_req)\n\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/executor/gpu_executor.py\u001b[0m in \u001b[0;36mexecute_model\u001b[0;34m(self, execute_model_req)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecute_model_req\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mExecuteModelRequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     ) -> Optional[List[Union[SamplerOutput, PoolerOutput]]]:\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver_worker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecute_model_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/worker/worker_base.py\u001b[0m in \u001b[0;36mexecute_model\u001b[0;34m(self, execute_model_req)\u001b[0m\n\u001b[1;32m    325\u001b[0m                     \"model_execute_time\", torch.tensor(0)).item()\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         output = self.model_runner.execute_model(\n\u001b[0m\u001b[1;32m    328\u001b[0m             \u001b[0mmodel_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0mkv_caches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mworker_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvirtual_engine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/worker/model_runner_base.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mtimestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y%m%d-%H%M%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/worker/model_runner.py\u001b[0m in \u001b[0;36mexecute_model\u001b[0;34m(self, model_input, kv_caches, intermediate_tensors, num_steps)\u001b[0m\n\u001b[1;32m   1699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1700\u001b[0m         \u001b[0;31m# Sample the next token.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1701\u001b[0;31m         output: SamplerOutput = self.model.sample(\n\u001b[0m\u001b[1;32m   1702\u001b[0m             \u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1703\u001b[0m             \u001b[0msampling_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampling_metadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/model_executor/models/llama.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, logits, sampling_metadata)\u001b[0m\n\u001b[1;32m    571\u001b[0m     def sample(self, logits: torch.Tensor,\n\u001b[1;32m    572\u001b[0m                sampling_metadata: SamplingMetadata) -> Optional[SamplerOutput]:\n\u001b[0;32m--> 573\u001b[0;31m         \u001b[0mnext_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/model_executor/layers/sampler.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, logits, sampling_metadata)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;31m# Sample the next tokens.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         maybe_deferred_sample_results, maybe_sampled_tokens_tensor = _sample(\n\u001b[0m\u001b[1;32m    278\u001b[0m             \u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mlogprobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/model_executor/layers/sampler.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(probs, logprobs, sampling_metadata, sampling_tensors, include_gpu_probs_tensor, modify_greedy_probs)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0msampled_token_ids_tensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0mof\u001b[0m \u001b[0msampled\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m     \"\"\"\n\u001b[0;32m--> 881\u001b[0;31m     return _sample_with_torch(\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m         \u001b[0mlogprobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/model_executor/layers/sampler.py\u001b[0m in \u001b[0;36m_sample_with_torch\u001b[0;34m(probs, logprobs, sampling_metadata, sampling_tensors, include_gpu_probs_tensor, modify_greedy_probs)\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0;31m# This also converts the sampler output to a Python object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;31m# Return Pythonized sampler result & sampled token ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m         return get_pythonized_sample_results(\n\u001b[0m\u001b[1;32m    851\u001b[0m             maybe_deferred_args), sampled_token_ids_tensor\n\u001b[1;32m    852\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/model_executor/layers/sampler.py\u001b[0m in \u001b[0;36mget_pythonized_sample_results\u001b[0;34m(sample_result_args)\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mseq_group_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_groups\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_metadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msampling_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msampling_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSamplingType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGREEDY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m             \u001b[0msample_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_greedy_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_groups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgreedy_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    715\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msampling_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSamplingType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRANDOM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSamplingType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRANDOM_SEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m             sample_results = _random_sample(seq_groups,\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vllm/model_executor/layers/sampler.py\u001b[0m in \u001b[0;36m_greedy_sample\u001b[0;34m(selected_seq_groups, samples)\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0mseq_group\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mdo_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \"\"\"\n\u001b[0;32m--> 479\u001b[0;31m     \u001b[0msamples_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m     \u001b[0msample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSampleResultType\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["temp= []\n","for i in range(0,len(df)):\n","    llm_prompt = generate_prompt(i)\n","    messages = [\n","        {\n","            \"role\": \"user\",\n","            \"content\": \" act as a survey analyzer for a beer consumption study. I will provide you with survey data, and you will analyze the responses, highlighting trends, preferences, and key insights related to beer consumption. You will also identify any correlations between user demographics and their beer preferences. Do not generate random interpretations but focus on extracting meaningful conclusions from the data provided.\" + llm_prompt \n","        },\n","        {\"role\": \"assistant\", \"content\": \"\"}  # Placeholder to ensure correct formatting\n","    ]\n","    text = tokenizer.apply_chat_template(\n","        messages,\n","        tokenize=False,\n","        add_generation_prompt=True\n","    )\n","    logit_bias = {28734: 93, 28740: 89}  # Force high probability for '0' and '1'\n","\n","    sampling_params = SamplingParams(\n","        temperature=0.0,  # No randomness\n","        top_k=2,          # Only consider '0' and '1'\n","        logit_bias=logit_bias,\n","        max_tokens=1,      # Ensure single-token response\n","    )\n","    outputs = llm.generate([text], sampling_params)\n","    generated_token_id = outputs[0].outputs[0].token_ids[0]\n","    generated_text = tokenizer.decode([generated_token_id])\n","    print(generated_text)\n","    print(\"\\n\")\n","    temp.append(generated_text)    "]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2025-03-11T06:13:26.224741Z","iopub.status.busy":"2025-03-11T06:13:26.224408Z","iopub.status.idle":"2025-03-11T06:13:26.229204Z","shell.execute_reply":"2025-03-11T06:13:26.228193Z","shell.execute_reply.started":"2025-03-11T06:13:26.224716Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["407\n"]}],"source":["print(len(temp))"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2025-03-11T06:13:40.945307Z","iopub.status.busy":"2025-03-11T06:13:40.944953Z","iopub.status.idle":"2025-03-11T06:13:40.950327Z","shell.execute_reply":"2025-03-11T06:13:40.949434Z","shell.execute_reply.started":"2025-03-11T06:13:40.945278Z"},"trusted":true},"outputs":[{"data":{"text/plain":["53"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["temp.count('1')"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2025-03-11T06:14:12.927877Z","iopub.status.busy":"2025-03-11T06:14:12.927580Z","iopub.status.idle":"2025-03-11T06:14:12.932297Z","shell.execute_reply":"2025-03-11T06:14:12.931389Z","shell.execute_reply.started":"2025-03-11T06:14:12.927854Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['0', '0', '1', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '1', '0', '0', '0', '0', '1', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '1', '1', '0', '0', '1', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '1', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '0', '1', '0', '0', '0', '0', '0', '0', '1', '0', '0', '1', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '1', '0', '0', '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '1', '0', '0', '0', '1', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0']\n"]}],"source":["print(temp)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5977063,"sourceId":9760679,"sourceType":"datasetVersion"},{"datasetId":6837684,"sourceId":10986117,"sourceType":"datasetVersion"},{"datasetId":6837699,"sourceId":10986143,"sourceType":"datasetVersion"},{"datasetId":6839647,"sourceId":10989033,"sourceType":"datasetVersion"}],"dockerImageVersionId":30919,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
